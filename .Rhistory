if(length(to_install) > 0){
install.packages(to_install, dependencies = TRUE)
}
rm(packages, to_install)
# GENERATE RMD ------------------------------------------------------------
suppressPackageStartupMessages(library(tidyverse))
db <- read_csv("data/database.csv", show_col_types = FALSE) |> filter(!is.na(value))
setwd("rutul_dialectology-master")
# GENERATE RMD ------------------------------------------------------------
suppressPackageStartupMessages(library(tidyverse))
db <- read_csv("data/database.csv", show_col_types = FALSE) |> filter(!is.na(value))
# create variable with leading 0 -------------------------------------------
db$filename <- str_c(sprintf(str_c("%0", nchar(max(db$feature_id)), "d_"),
db$feature_id),
str_replace_all(db$feature_title, "[\\s:\\./]", "_"),
".qmd")
to_remove <- list.files(".", pattern = ".qmd")
to_remove <- to_remove[!(to_remove %in% c("index.qmd", "team.qmd", "features.qmd"))]
file.remove(c(to_remove, list.files(".", pattern = ".html")))
options(ymlthis.rmd_body = "
```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE, fig.width = 9.5)
library(tidyverse)
library(lingtypology)
read_csv('data/database.csv', show_col_types = FALSE) |>
filter(feature_id == PUT_FEATURE_ID_HERE) ->
db
read_csv('data/villages.csv') |>
filter(!(village %in% c('Kazankulak', 'Novyy Borch', 'Vrush', 'Aran', 'Khnyukh'))) ->
villages
villages |>
filter(!(village %in% c('Tsudik', 'Borch'))) ->
villages4map
```
PUT_FEATURE_DESCRIPTION_HERE
")
make_section <- function(section_title){
glue::glue("
## {section_title}
::: {{.panel-tabset}}
### Map
```{{r}}
db |>
filter(feature_lexeme == '{section_title}')  |>
filter(!is.na(value),
value != 'NO DATA') |>
mutate(value = str_split(value, ' ; ')) |>
unnest_longer(value) |>
distinct(settlement, value) |>
mutate(n = 1) |>
pivot_wider(names_from = value, values_from = n, values_fill = 0) |>
left_join(villages[,c('village', 'lat', 'lon')], c('settlement' = 'village')) |>
mutate(language = 'Rutul') ->
for_map
if(length(for_map) == 5){{
map.feature(languages = 'Rutul',
latitude = villages4map$lat,
longitude = villages4map$lon,
label = villages4map$village,
label.position = 'top',
label.hide = FALSE,
width = 10,
color = 'gray',
tile = 'OpenStreetMap.HOT',
opacity = 0.4) |>
map.feature(languages = for_map$language,
latitude = for_map$lat,
longitude = for_map$lon,
label = for_map$settlement,
label.position = 'top',
label.hide = FALSE,
width = 10,
tile = 'OpenStreetMap.HOT',
features = colnames(for_map)[2],
pipe.data = _)
}} else {{
map.feature(languages = 'Rutul',
latitude = villages4map$lat,
longitude = villages4map$lon,
label = villages4map$village,
label.position = 'top',
label.hide = FALSE,
width = 10,
color = 'gray',
tile = 'OpenStreetMap.HOT',
opacity = 0.4) |>
map.feature(languages = for_map$language,
latitude = for_map$lat,
longitude = for_map$lon,
minichart.data = for_map |> select(-settlement, -lat, -lon, -language),
minichart = 'pie',
width = 3,
tile = 'OpenStreetMap.HOT',
pipe.data = _)
}}
```
### Data
```{{r}}
db |>
filter(feature_lexeme == '{section_title}') |>
select(settlement, value, stimuli, answer, collected) |>
DT::datatable(class = 'cell-border stripe',
rownames = FALSE,
filter = 'top',
extensions = 'Buttons',
options = list(pageLength = 42,
autoWidth = TRUE,
info = FALSE,
dom = 'fBltp',
buttons = list(list(extend = 'collection',
buttons = c('csv', 'excel', 'pdf'),
text = '<i class=\"fas fa-download\"></i>')),
paginate = TRUE))
```
:::
")
}
db |>
distinct(feature_id, feature_title, feature_description, compiled,
updated_day, updated_month, updated_year, filename, feature_lexeme) |>
count(feature_id, feature_title, feature_description, compiled,
updated_day, updated_month, updated_year, filename) |>
mutate(number_section = n > 1) ->
rmd_creation
library(ymlthis)
walk(rmd_creation$feature_id, function(i){
yml_empty() |>
yml_title(rmd_creation$feature_title[i]) |>
yml_author(rmd_creation$compiled[i]) |>
yml_date(str_c('Last update: ',
'`r lubridate::make_datetime(year = ',
rmd_creation$updated_year[i],
', month = ',
rmd_creation$updated_month[i],
', day = ',
rmd_creation$updated_day[i],
')`')) |>
yml_output(html_document(number_sections = TRUE,
anchor_sections = TRUE,
pandoc_args = "--shift-heading-level-by=-1")) |>
use_rmarkdown(path = rmd_creation$filename[i],
open_doc = FALSE,
quiet = TRUE,
include_body = FALSE,
body = NULL)
db |>
filter(feature_id == i) |>
pull(feature_lexeme) |>
unique() |>
map(make_section) |>
write_lines(rmd_creation$filename[i], append = TRUE)
t <- read_lines(rmd_creation$filename[i])
# change id
t[str_which(t, "PUT_FEATURE_ID_HERE")] <-
str_replace(t[str_which(t, "PUT_FEATURE_ID_HERE")],
"PUT_FEATURE_ID_HERE",
as.character(rmd_creation$feature_id[i]))
# change text
t[str_which(t, "PUT_FEATURE_DESCRIPTION_HERE")] <-
str_replace(t[str_which(t, "PUT_FEATURE_DESCRIPTION_HERE")],
"PUT_FEATURE_DESCRIPTION_HERE",
as.character(rmd_creation$feature_description[i]))
# fix in case there is no feature_lexeme
t[str_which(t, "\\#\\# NA")] <-
str_replace(t[str_which(t, "\\#\\# NA")], "\\#\\# NA", "##")
# fix section enumiration
if(!rmd_creation$number_section[i]){
t[str_which(t, "    number_sections: true")] <-
str_replace(t[str_which(t, "    number_sections: true")],
"    number_sections: true",
"    number_sections: false")
}
t <- t[str_which(t, "feature_lexeme == 'NA'", negate = TRUE)]
write_lines(t, rmd_creation$filename[i])
})
library(quarto)
quarto_render(profile = "english")
quarto render
getwd()
setwd("rutul_dialectology-master")
quarto render
quarto::quarto_render()\
quarto::quarto_render()
# install packages ---------------------------------------------------------
packages <- c("tidyverse", "quarto", "lingtypology", "DT", "knitr", "ymlthis",
"lubridate", "stringr")
to_install <- packages[!(packages %in% installed.packages())]
if(length(to_install) > 0){
install.packages(to_install, dependencies = TRUE)
}
rm(packages, to_install)
# GENERATE RMD ------------------------------------------------------------
suppressPackageStartupMessages(library(tidyverse))
db <- read_csv("data/database.csv", show_col_types = FALSE) |> filter(!is.na(value))
# create variable with leading 0 -------------------------------------------
db$filename <- str_c(sprintf(str_c("%0", nchar(max(db$feature_id)), "d_"),
db$feature_id),
str_replace_all(db$feature_title, "[\\s:\\./]", "_"),
".qmd")
to_remove <- list.files(".", pattern = ".qmd")
to_remove <- to_remove[!(to_remove %in% c("index.qmd", "team.qmd", "features.qmd"))]
file.remove(c(to_remove, list.files(".", pattern = ".html")))
options(ymlthis.rmd_body = "
```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE, fig.width = 9.5)
library(tidyverse)
library(lingtypology)
read_csv('data/database.csv', show_col_types = FALSE) |>
filter(feature_id == PUT_FEATURE_ID_HERE) ->
db
read_csv('data/villages.csv') |>
filter(!(village %in% c('Kazankulak', 'Novyy Borch', 'Vrush', 'Aran', 'Khnyukh'))) ->
villages
villages |>
filter(!(village %in% c('Tsudik', 'Borch'))) ->
villages4map
```
PUT_FEATURE_DESCRIPTION_HERE
")
make_section <- function(section_title){
glue::glue("
## {section_title}
::: {{.panel-tabset}}
### Map
```{{r}}
db |>
filter(feature_lexeme == '{section_title}')  |>
filter(!is.na(value),
value != 'NO DATA') |>
mutate(value = str_split(value, ' ; ')) |>
unnest_longer(value) |>
distinct(settlement, value) |>
mutate(n = 1) |>
pivot_wider(names_from = value, values_from = n, values_fill = 0) |>
left_join(villages[,c('village', 'lat', 'lon')], c('settlement' = 'village')) |>
mutate(language = 'Rutul') ->
for_map
if(length(for_map) == 5){{
map.feature(languages = 'Rutul',
latitude = villages4map$lat,
longitude = villages4map$lon,
label = villages4map$village,
label.position = 'top',
label.hide = FALSE,
width = 10,
color = 'gray',
tile = 'OpenStreetMap.HOT',
opacity = 0.4) |>
map.feature(languages = for_map$language,
latitude = for_map$lat,
longitude = for_map$lon,
label = for_map$settlement,
label.position = 'top',
label.hide = FALSE,
width = 10,
tile = 'OpenStreetMap.HOT',
features = colnames(for_map)[2],
pipe.data = _)
}} else {{
map.feature(languages = 'Rutul',
latitude = villages4map$lat,
longitude = villages4map$lon,
label = villages4map$village,
label.position = 'top',
label.hide = FALSE,
width = 10,
color = 'gray',
tile = 'OpenStreetMap.HOT',
opacity = 0.4) |>
map.feature(languages = for_map$language,
latitude = for_map$lat,
longitude = for_map$lon,
minichart.data = for_map |> select(-settlement, -lat, -lon, -language),
minichart = 'pie',
width = 3,
tile = 'OpenStreetMap.HOT',
pipe.data = _)
}}
```
### Data
```{{r}}
db |>
filter(feature_lexeme == '{section_title}') |>
select(settlement, value, stimuli, answer, collected) |>
DT::datatable(class = 'cell-border stripe',
rownames = FALSE,
filter = 'top',
extensions = 'Buttons',
options = list(pageLength = 42,
autoWidth = TRUE,
info = FALSE,
dom = 'fBltp',
buttons = list(list(extend = 'collection',
buttons = c('csv', 'excel', 'pdf'),
text = '<i class=\"fas fa-download\"></i>')),
paginate = TRUE))
```
:::
")
}
db |>
distinct(feature_id, feature_title, feature_description, compiled,
updated_day, updated_month, updated_year, filename, feature_lexeme) |>
count(feature_id, feature_title, feature_description, compiled,
updated_day, updated_month, updated_year, filename) |>
mutate(number_section = n > 1) ->
rmd_creation
library(ymlthis)
walk(rmd_creation$feature_id, function(i){
yml_empty() |>
yml_title(rmd_creation$feature_title[i]) |>
yml_author(rmd_creation$compiled[i]) |>
yml_date(str_c('Last update: ',
'`r lubridate::make_datetime(year = ',
rmd_creation$updated_year[i],
', month = ',
rmd_creation$updated_month[i],
', day = ',
rmd_creation$updated_day[i],
')`')) |>
yml_output(html_document(number_sections = TRUE,
anchor_sections = TRUE,
pandoc_args = "--shift-heading-level-by=-1")) |>
use_rmarkdown(path = rmd_creation$filename[i],
open_doc = FALSE,
quiet = TRUE,
include_body = FALSE,
body = NULL)
db |>
filter(feature_id == i) |>
pull(feature_lexeme) |>
unique() |>
map(make_section) |>
write_lines(rmd_creation$filename[i], append = TRUE)
t <- read_lines(rmd_creation$filename[i])
# change id
t[str_which(t, "PUT_FEATURE_ID_HERE")] <-
str_replace(t[str_which(t, "PUT_FEATURE_ID_HERE")],
"PUT_FEATURE_ID_HERE",
as.character(rmd_creation$feature_id[i]))
# change text
t[str_which(t, "PUT_FEATURE_DESCRIPTION_HERE")] <-
str_replace(t[str_which(t, "PUT_FEATURE_DESCRIPTION_HERE")],
"PUT_FEATURE_DESCRIPTION_HERE",
as.character(rmd_creation$feature_description[i]))
# fix in case there is no feature_lexeme
t[str_which(t, "\\#\\# NA")] <-
str_replace(t[str_which(t, "\\#\\# NA")], "\\#\\# NA", "##")
# fix section enumiration
if(!rmd_creation$number_section[i]){
t[str_which(t, "    number_sections: true")] <-
str_replace(t[str_which(t, "    number_sections: true")],
"    number_sections: true",
"    number_sections: false")
}
t <- t[str_which(t, "feature_lexeme == 'NA'", negate = TRUE)]
write_lines(t, rmd_creation$filename[i])
})
library(quarto)
quarto_render(profile = "english")
quarto_render(profile = "english")
quarto_render(profile = "russian")
getwd()
library(conflicted)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
library(tidyverse)
# asya and kostya -----------------------------------------------------------
df <- read_csv("data/noun_features_coding.csv")
df |>
filter(to_map == 1) |>
mutate(feature_id = as.double(factor(feature_title)),
compiled = "Asya Alekseeva") |>
select(feature_id, feature_title, feature_lexeme, feature_description, collected, compiled, updated_day,
updated_month, updated_year, domain, settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "")
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
df <- read_csv("data/nikita_phonology_3.csv")
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description, collected, compiled, updated_day,
updated_month, updated_year, domain, settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "", append = TRUE)
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
df <- read_csv("data/rutul_dialectology_ilya.csv")
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description, collected, compiled, updated_day,
updated_month, updated_year, domain, settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "", append = TRUE)
# add Garik's lexicon -----------------------------------------------------
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
read_csv("data/lexicon_moroz_full_ready.csv") |>
filter(!is.na(value),
value != "boring") ->
df
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description, collected, compiled, updated_day,
updated_month, updated_year, domain, settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "", append = TRUE)
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
readr::read_csv("data/verb_2025-23-08.csv") |>
filter(!is.na(value)) ->
df
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description, collected, compiled, updated_day,
updated_month, updated_year, domain, settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "", append = TRUE)
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
readr::read_csv("data/NINA rutul_dialectology_merged_raw_data.csv") |>
filter(!is.na(value)) ->
df
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description, collected, compiled, updated_day,
updated_month, updated_year, domain, settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "", append = TRUE)
# add Maxim's demonstratives ----------------------------------------------
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
readr::read_csv("data/other_features_Maks.csv") |>
filter(!is.na(value)) ->
df
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description,
collected, compiled, updated_day, updated_month, updated_year, domain,
settlement, value, stimuli, answer) |>
arrange(feature_id) |>
write_csv("data/database.csv", na = "", append = TRUE)
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
read_csv("data/netkachev_Rutul_data.csv") |>
filter(!is.na(value)) ->
df
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description,
collected, compiled, updated_day, updated_month, updated_year, domain,
settlement, value, stimuli, answer) |>
arrange(feature_id)  |>
write_csv("data/database.csv", na = "", append = TRUE)
read_csv("data/database.csv", col_select = "feature_id") |>
distinct() |>
filter(feature_id == max(feature_id)) |>
pull(feature_id) ->
max_id_in_db
read_tsv("data/rutul_dialects_200.tsv") |>
filter(!is.na(value)) ->
df
df |>
mutate(feature_id = as.double(factor(feature_title))+max_id_in_db) |>
select(feature_id, feature_title, feature_lexeme, feature_description,
collected, compiled, updated_day, updated_month, updated_year, domain,
settlement, value, stimuli, answer) |>
arrange(feature_id)  |>
write_csv("data/database.csv", na = "", append = TRUE)
read_csv("data/database.csv") |>
mutate_at(c("collected", "compiled", "domain", "settlement"), str_to_title) |>
mutate(feature_title = str_replace_all(feature_title, "'", "’"),
feature_lexeme = str_replace_all(feature_lexeme, "'", "’"),
value = str_replace_all(value, "\\s{2,}", " ")) |>
write_csv("data/database.csv", na = "")
read_csv("data/database.csv") |>
writexl::write_xlsx("data/database.xlsx")
reticulate::repl_python()
install.packages("reticulate")
install.packages("reticulate")
library(reticulate)
reticulate::repl_python()
py_config()
py_install("pandas")
reticulate::repl_python()
library(quarto)
Reporting dialectal differences in the Atlas is based exclusively on the data obtained in our elicitations. Therefore, it is possible that a certain feature value is absent from our data for a village while it has been reported for the same village in the literature. In other words, the Atlas is only a partial reflection of the dialectal diversity of Rutul.
reticulate::repl_python()
reticulate::py_install("openpyxl")
reticulate::repl_python()
